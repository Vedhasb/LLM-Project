# -*- coding: utf-8 -*-
"""ROUND1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11E3ebrrMpoDSnEV1zKQoplimrbOM3Hzd
"""

!pip install pandas numpy scikit-learn matplotlib seaborn transformers

import pandas as pd

# Load the dataset
file_path = "Hackathon_Round_1.xlsx"  # Update the file name if necessary
data = pd.read_excel(file_path)

# Display the first few rows
print(data.head())
print(data.info())

import pandas as pd

# Load the dataset
file_path = "Hackathon_Round_1.xlsx"  # Replace with the correct path if needed
data = pd.read_excel(file_path)

# Display the first few rows to confirm successful loading
print(data.head())

# Check for missing values
print(data.isnull().sum())

# Handle missing values if necessary
data = data.dropna()

print(data.columns)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

file_path = "Hackathon_Round_1.xlsx"
data = pd.read_excel("/content/Hackathon_Round_1.xlsx")

print("Column Names:", data.columns)
print(data.head())

data.columns = data.columns.str.strip()

print("Missing Values:", data.isnull().sum())
data = data.dropna()

print("Column Names After Cleaning:", data.columns)

first_level_label_column = "subtask_a"  # Update with actual column name
second_level_label_column = "subtask_b"  # Update with actual column name
tweet_content_column = "Text"  # Update with the column containing tweets

label_encoder_first = LabelEncoder()
label_encoder_second = LabelEncoder()

data[first_level_label_column] = label_encoder_first.fit_transform(data[first_level_label_column])
data[second_level_label_column] = label_encoder_second.fit_transform(data[second_level_label_column])

X = data[tweet_content_column]
y_first = data[first_level_label_column]
y_second = data[second_level_label_column]

X_train_first, X_test_first, y_train_first, y_test_first = train_test_split(X, y_first, test_size=0.2, random_state=42)

X_train_second, X_test_second, y_train_second, y_test_second = train_test_split(X, y_second, test_size=0.2, random_state=42)

tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words="english")

X_train_tfidf_first = tfidf_vectorizer.fit_transform(X_train_first)
X_test_tfidf_first = tfidf_vectorizer.transform(X_test_first)

X_train_tfidf_second = tfidf_vectorizer.fit_transform(X_train_second)
X_test_tfidf_second = tfidf_vectorizer.transform(X_test_second)

clf_first = RandomForestClassifier(n_estimators=100, random_state=42)
clf_first.fit(X_train_tfidf_first, y_train_first)

y_pred_first = clf_first.predict(X_test_tfidf_first)
print("First-Level Classification Report:")
print(classification_report(y_test_first, y_pred_first, target_names=label_encoder_first.classes_))

clf_second = RandomForestClassifier(n_estimators=10, random_state=42)
clf_second.fit(X_train_tfidf_second, y_train_second)

y_pred_second = clf_second.predict(X_test_tfidf_second)
print("Second-Level Classification Report:")
print(classification_report(y_test_second, y_pred_second, target_names=label_encoder_second.classes_))

results = pd.DataFrame({"Tweet_Content": X_test_first,
                        "First_Level_True": y_test_first,
                        "First_Level_Pred": y_pred_first,
                        "Second_Level_True": y_test_second,
                        "Second_Level_Pred": y_pred_second})

results.to_csv("classification_results.csv", index=False)
print("Results saved to classification_results.csv")

pip install textblob

from textblob import TextBlob

# Function to compute sentiment
def get_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity > 0:
        return "Positive"
    elif analysis.sentiment.polarity == 0:
        return "Neutral"
    else:
        return "Negative"

# Apply sentiment analysis to the test dataset
X_test_sentiments = X_test_first.apply(get_sentiment)

# Display sentiment distribution
print("Sentiment Distribution:")
print(X_test_sentiments.value_counts())

results["Sentiment"] = X_test_sentiments
results.to_csv("classification_results_with_sentiment.csv", index=False)
print("Results with sentiment analysis saved to classification_results_with_sentiment.csv")

import matplotlib.pyplot as plt

# Plot sentiment distribution
X_test_sentiments.value_counts().plot(kind='bar', color=['green', 'blue', 'red'])
plt.title("Sentiment Distribution of Tweets")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.show()

